{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035857ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "\n",
    "import time\n",
    "import datetime as dt\n",
    "from datetime import timedelta, datetime, timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5dda0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb36ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rse_coord = '도솔대교_RSE_위도경도.csv'\n",
    "\n",
    "df = pd.read_csv(rse_coord)\n",
    "\n",
    "map = folium.Map(tiles = \"OpenStreetMap\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    folium.CircleMarker(location=[row['latitude'], row['longitude']], radius = 3, weight = 3, tooltip = row['rse_id']+row['node_nm'], color='red').add_to(map)\n",
    "    \n",
    "map.fit_bounds(map.get_bounds())\n",
    "\n",
    "#map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65b011b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_id = {}\n",
    "id_name = {}\n",
    "id_lat = {}\n",
    "id_long = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    name_id[row['node_nm']] = row['rse_id']\n",
    "    id_name[row['rse_id']] = row['node_nm']\n",
    "    id_lat[row['rse_id']] = row['latitude']\n",
    "    id_long[row['rse_id']] = row['longitude']\n",
    "#print(rse_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "190c7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, orig, orig_id, dest, dest_id, direction):\n",
    "        self.origin = orig\n",
    "        self.orig_id = orig_id\n",
    "        self.dest = dest\n",
    "        self.dest_id = dest_id\n",
    "        self.direction = direction\n",
    "        \n",
    "#도솔대교 Node\n",
    "Links = ['옥녀봉삼거리,도안동로입구','도안동로입구,옥녀봉삼거리',\n",
    "         '옥녀봉네거리,옥녀봉삼거리','옥녀봉삼거리,옥녀봉네거리',\n",
    "         '옥녀봉네거리,도솔네거리','도솔네거리,옥녀봉네거리',\n",
    "         '도솔네거리,안골네거리','안골네거리,도솔네거리',\n",
    "         '옥녀봉네거리,위더스타워네거리','위더스타워네거리,옥녀봉네거리',\n",
    "         '도로교통공단대전충남지부앞,위더스타워네거리','위더스타워네거리,도로교통공단대전충남지부앞',\n",
    "         '옥녀봉네거리,원신흥로입구','원신흥로입구,옥녀봉네거리',\n",
    "         '원신흥로입구,원신흥북로종점','원신흥북로종점,원신흥로입구',\n",
    "         '도안호반베르디움201동삼거리,원신흥북로종점','원신흥북로종점,도안호반베르디움201동삼거리',\n",
    "         '도안호반베르디움201동삼거리,진터지하차도','진터지하차도,도안호반베르디움201동삼거리',\n",
    "         '도안호반베르디움201동삼거리,용반네거리','용반네거리,도안호반베르디움201동삼거리',\n",
    "         '유성네거리,계룡로132번길','계룡로132번길,유성네거리',\n",
    "         '계룡로132번길,용반네거리','용반네거리,계룡로132번길',\n",
    "         '용반네거리,만년교네거리','만년교네거리,용반네거리',\n",
    "         '만년교네거리,월평초교삼거리','월평초교삼거리,만년교네거리',\n",
    "         '갑천대교네거리,월평초교삼거리','월평초교삼거리,갑천대교네거리',\n",
    "         '갑천대교네거리,갑천네거리','갑천네거리,갑천대교네거리',\n",
    "         '만년교네거리,도안호반베르디움201동삼거리','도안호반베르디움201동삼거리,만년교네거리',\n",
    "         '만년교네거리,원신흥로입구','원신흥로입구,만년교네거리']\n",
    "\n",
    "Names = []\n",
    "\n",
    "for i in Links:\n",
    "    j = i.split(\",\")[0]\n",
    "    k = i.split(\",\")[1]\n",
    "    if(j not in Names):\n",
    "        Names.append(j)\n",
    "    if(k not in Names):\n",
    "        Names.append(k)\n",
    "\n",
    "Names.sort()\n",
    "        \n",
    "Nodelist = []\n",
    "\n",
    "for i in Links:\n",
    "    j = i.split(\",\")[0]\n",
    "    k = i.split(\",\")[1]\n",
    "    Nodelist.append(Node(j, name_id[j], k, name_id[k], j+'->'+k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f33bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames23 = []\n",
    "filenames24 = []\n",
    "\n",
    "year = ['2023', '2024']\n",
    "month = ['2월', '3월', '4월']\n",
    "hours = ['0708', '0809', '0709', '1213', '1314', '1214', '1718', '1819', '1719']\n",
    "peak = ['오전첨두', '비첨두', '오후첨두']\n",
    "\n",
    "for y in year:\n",
    "    for m in month:\n",
    "        for i in range(3):\n",
    "            for k in range(3):\n",
    "                filename = y + '_' + m + '_' + peak[i] + '_' + hours[3*i + k] + '.csv'\n",
    "                if(y == '2023'):\n",
    "                    filenames23.append(filename)\n",
    "                if(y == '2024'):\n",
    "                    filenames24.append(filename)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d18501d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2월_오전첨두_07:00~08:00', '2월_오전첨두_08:00~09:00', '2월_오전첨두_07:00~09:00', '2월_비첨두_12:00~13:00', '2월_비첨두_13:00~14:00', '2월_비첨두_12:00~14:00', '2월_오후첨두_17:00~18:00', '2월_오후첨두_18:00~19:00', '2월_오후첨두_17:00~19:00', '3월_오전첨두_07:00~08:00', '3월_오전첨두_08:00~09:00', '3월_오전첨두_07:00~09:00', '3월_비첨두_12:00~13:00', '3월_비첨두_13:00~14:00', '3월_비첨두_12:00~14:00', '3월_오후첨두_17:00~18:00', '3월_오후첨두_18:00~19:00', '3월_오후첨두_17:00~19:00', '4월_오전첨두_07:00~08:00', '4월_오전첨두_08:00~09:00', '4월_오전첨두_07:00~09:00', '4월_비첨두_12:00~13:00', '4월_비첨두_13:00~14:00', '4월_비첨두_12:00~14:00', '4월_오후첨두_17:00~18:00', '4월_오후첨두_18:00~19:00', '4월_오후첨두_17:00~19:00']\n"
     ]
    }
   ],
   "source": [
    "dates = ['2월', '3월','4월']\n",
    "times = ['오전첨두', '비첨두', '오후첨두']\n",
    "hours = [['07:00~08:00', '08:00~09:00', '07:00~09:00'],\n",
    "         ['12:00~13:00', '13:00~14:00', '12:00~14:00'],\n",
    "         ['17:00~18:00', '18:00~19:00', '17:00~19:00']]\n",
    "dates_times_hours = []\n",
    "\n",
    "for d in dates:\n",
    "    for i in range(3):\n",
    "        time = times[i]\n",
    "        hour = hours[i]\n",
    "        for t in hour:\n",
    "            dates_times_hours.append(d+'_'+time+'_'+t)\n",
    "\n",
    "print(dates_times_hours)\n",
    "\n",
    "### filenames\n",
    "\n",
    "#filenames23 = ['2023_4월_오전첨두_0708.csv', '2023_4월_오전첨두_0809.csv', '2023_4월_오전첨두_0709.csv', \n",
    "#               '2023_4월_비첨두_1213.csv', '2023_4월_비첨두_1314.csv', '2023_4월_비첨두_1214.csv',\n",
    "#               '2023_4월_오후첨두_1718.csv', '2023_4월_오후첨두_1819.csv', '2023_4월_오후첨두_1719.csv']\n",
    "#filenames24 = ['2024_4월_오전첨두_0708.csv', '2024_4월_오전첨두_0809.csv', '2024_4월_오전첨두_0709.csv', \n",
    "#               '2024_4월_비첨두_1213.csv', '2024_4월_비첨두_1314.csv', '2024_4월_비첨두_1214.csv',\n",
    "#               '2024_4월_오후첨두_1718.csv', '2024_4월_오후첨두_1819.csv', '2024_4월_오후첨두_1719.csv']\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "dfdict = {}\n",
    "\n",
    "t = 0\n",
    "for dth in dates_times_hours:\n",
    "    result = pd.DataFrame(columns = ['route_id', 'origin_RSE_id', 'destin_RSE_id', 'lon_origin', 'lat_origin', 'lon_destin', \n",
    "                                     'lat_destin', 'movers_2023', 'movers_2024', 'avg_speed_2023', 'avg_speed_2024',\n",
    "                                      'avg_time_2023', 'avg_time_2024', \n",
    "                                      'movers_diff', 'avg_speed_diff', 'avg_time_diff', 'direction'])\n",
    "    df23 = pd.read_csv('도솔대교_정책보고서_RSE데이터/' + filenames23[t])\n",
    "    df24 = pd.read_csv('도솔대교_정책보고서_RSE데이터/' + filenames24[t])\n",
    "    \n",
    "    i = 0\n",
    "    for node in Nodelist:\n",
    "        row23 = df23.loc[(df23['start_rse'] == node.orig_id) & (df23['end_rse'] == node.dest_id)]\n",
    "        row24 = df24.loc[(df24['start_rse'] == node.orig_id) & (df24['end_rse'] == node.dest_id)]\n",
    "        \n",
    "        route_id = i\n",
    "        origin_RSE_id = node.orig_id\n",
    "        destin_RSE_id = node.dest_id\n",
    "        lon_origin = id_long[node.orig_id]\n",
    "        lat_origin = id_lat[node.orig_id]\n",
    "        lon_destin = id_long[node.dest_id]\n",
    "        lat_destin = id_lat[node.dest_id]\n",
    "        \n",
    "        try:\n",
    "            movers23 = row23['frequency'].iloc[0]\n",
    "        except:\n",
    "            movers23 = 0\n",
    "        try:\n",
    "            movers24 = row24['frequency'].iloc[0]\n",
    "        except:\n",
    "            movers24 = 0\n",
    "        try:\n",
    "            avg_speed23 = row23['avg_speed'].iloc[0]\n",
    "        except:\n",
    "            avg_speed23 = 0\n",
    "        try:\n",
    "            avg_speed24 = row24['avg_speed'].iloc[0]\n",
    "        except:\n",
    "            avg_speed24 = 0\n",
    "        try:\n",
    "            avg_time23 = row23['avg_time'].iloc[0]\n",
    "        except:\n",
    "            avg_time23 = 0\n",
    "        try:\n",
    "            avg_time24 = row24['avg_time'].iloc[0]\n",
    "        except:\n",
    "            avg_time24 = 0\n",
    "        \n",
    "        try:\n",
    "            movers = row24['frequency'].iloc[0] - row23['frequency'].iloc[0]\n",
    "        except:\n",
    "            movers = 0\n",
    "        \n",
    "        try:\n",
    "            avg_speed = row24['avg_speed'].iloc[0] - row23['avg_speed'].iloc[0]\n",
    "        except:\n",
    "            avg_speed = 0\n",
    "        \n",
    "        try:\n",
    "            avg_time = row24['avg_time'].iloc[0] - row23['avg_time'].iloc[0]\n",
    "        except:\n",
    "            avg_time = 0\n",
    "        \n",
    "        direction = node.direction\n",
    "        \n",
    "        data = [{'route_id' : route_id, 'origin_RSE_id' : origin_RSE_id, 'destin_RSE_id' : destin_RSE_id,\n",
    "                 'lon_origin' : lon_origin, 'lat_origin' : lat_origin, 'lon_destin' : lon_destin,\n",
    "                 'lat_destin' : lat_destin, 'movers_2023' : movers23, 'movers_2024' : movers24,\n",
    "                 'avg_speed_2023' : avg_speed23, 'avg_speed_2024' : avg_speed24,\n",
    "                 'avg_time_2023' : avg_time23, 'avg_time_2024' : avg_time24,\n",
    "                 'movers_diff' : movers, 'avg_speed_diff' : avg_speed, 'avg_time_diff' : avg_time,\n",
    "                 'direction' : direction}]\n",
    "        \n",
    "        resapp = pd.DataFrame(data)\n",
    "        \n",
    "        result = pd.concat([result, resapp], ignore_index=True)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    dfdict[dth] = result\n",
    "    \n",
    "    result_name = 'results/' + dth + '.csv'\n",
    "    result_name = result_name.replace(':', '')\n",
    "    result_name = result_name.replace('00', '')\n",
    "    result.to_csv(result_name, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b39a5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
